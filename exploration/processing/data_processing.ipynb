{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "import re\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "import warnings\n",
    "import pdfplumber\n",
    "from spellchecker import SpellChecker\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"../data/Study permit_ Get the right documents - Canada.ca.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_headers_and_footers(pdf_path):\n",
    "    header = \"\"\n",
    "    footers = []\n",
    "    ref_link = \"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            txt = page.extract_text_lines()\n",
    "            \n",
    "            if not header:\n",
    "                header = txt[0]['text']\n",
    "                \n",
    "            footer = txt[-1]['text']\n",
    "            if footer not in footers:\n",
    "                footers.append(footer)\n",
    "                \n",
    "            ref_link = footer.split()[0]\n",
    "                \n",
    "    return header, footers, ref_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "header, footers, ref_link = detect_headers_and_footers(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_content(content, txt_removed=None):\n",
    "    content = content.encode('utf-8').decode('utf-8')\n",
    "    content = re.sub(r'\\ue107', '', content)\n",
    "    content = re.sub(r'\\n', ' ', content)\n",
    "    content = content.replace(f'{header}', '')\n",
    "    for txt in txt_removed:\n",
    "        content = content.replace(txt, '')\n",
    "    content = re.sub(r'\\ue092 Date modified: \\d\\d\\d\\d-\\d\\d-\\d\\d', '', content)\n",
    "    for footer in footers:\n",
    "        content = content.replace(footer, '')\n",
    "    content = re.sub(r'\\s+', ' ', content)\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hyperlinks(pdf_path):\n",
    "    hyperlinks = []\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for _, page in enumerate(pdf.pages):\n",
    "            for annotation in page.annots:\n",
    "                if str(annotation['uri']).startswith(r'http://') or str(annotation['uri']).startswith(r'https://'):\n",
    "                    uri = annotation.get(\"uri\", None)\n",
    "                    if uri:\n",
    "                        # Get the bounding box coordinates for the link\n",
    "                        x0, y0, x1, y1 = annotation['x0'], annotation['top'], annotation['x1'], annotation['bottom']\n",
    "                        \n",
    "                        # Extract text within the bounding box\n",
    "                        text_content = \"\"\n",
    "                        for char in page.chars:\n",
    "                            if x0 <= char['x0'] and char['x1'] <= x1 and y0 <= char['top'] and char['bottom'] <= y1:\n",
    "                                text_content += char.get('text', '')\n",
    "                        \n",
    "                        hyperlink = {\n",
    "                            \"uri\": uri,\n",
    "                            \"text\": text_content.strip()\n",
    "                        }\n",
    "                        hyperlinks.append(hyperlink)\n",
    "    return hyperlinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_section_with_content(pdf_path, skip_tags=None, category=None):\n",
    "    if skip_tags is None:\n",
    "        skip_tags = []\n",
    "    \n",
    "    sections_with_content = []\n",
    "    current_section = None\n",
    "    current_subsection = None\n",
    "    current_content = []\n",
    "    subsection_indexes = {}\n",
    "    \n",
    "    \n",
    "    SECTION_MIN_SIZE = 28\n",
    "    SECTION_MAX_SIZE = 29\n",
    "    SUBSECTION_MIN_SIZE = 26\n",
    "    SUBSECTION_MAX_SIZE = 27\n",
    "    \n",
    "\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page_num, page in enumerate(pdf.pages):\n",
    "            text_with_coords = page.extract_text_lines()\n",
    "            for line in text_with_coords:\n",
    "                text = line['text']\n",
    "                \n",
    "                if line['chars'][0]['fontname'] == 'CAAAAA+Lato-Bold' and SECTION_MIN_SIZE <= line['chars'][0]['size'] < SECTION_MAX_SIZE:\n",
    "                    if current_section and current_content:\n",
    "                        sections_with_content[-1]['content'] = ' '.join(current_content).strip()\n",
    "                    if text not in skip_tags:  # Skip section if in skip_tags\n",
    "                        current_section = line['text']\n",
    "                        current_content = []\n",
    "                        if category != None:\n",
    "                            sections_with_content.append({\n",
    "                                'tag': category,\n",
    "                                'section': current_section,\n",
    "                                'subsections': [],\n",
    "                                'content': ''\n",
    "                            })\n",
    "                        else:\n",
    "                            sections_with_content.append({\n",
    "                                'section': current_section,\n",
    "                                'subsections': [],\n",
    "                                'content': ''\n",
    "                            })\n",
    "                        section_index = len(sections_with_content) - 1\n",
    "                        subsection_indexes = {}\n",
    "                elif line['chars'][0]['fontname'] == 'CAAAAA+Lato-Bold' and SUBSECTION_MIN_SIZE <= line['chars'][0]['size'] < SUBSECTION_MAX_SIZE:\n",
    "                    if current_subsection and current_content:\n",
    "                        subsection_content = current_subsection + \": \" + clean_content(' '.join(current_content).strip())\n",
    "                        if current_subsection in subsection_indexes:\n",
    "                            sections_with_content[section_index]['subsections'][subsection_indexes[current_subsection]]['content'] = subsection_content\n",
    "                        else:\n",
    "                            if current_subsection not in skip_tags:  # Skip subsection if in skip_tags\n",
    "                                sections_with_content[section_index]['subsections'].append({\n",
    "                                    'content': subsection_content\n",
    "                                })\n",
    "                                subsection_indexes[current_subsection] = len(sections_with_content[section_index]['subsections']) - 1\n",
    "                    current_subsection = line['text']\n",
    "                    current_content = []\n",
    "                elif current_subsection != \"On this page\":\n",
    "                    current_content.append(line['text'])\n",
    "                  \n",
    "                    \n",
    "                if current_subsection and current_content:\n",
    "                    subsection_content = current_subsection + \": \" + clean_content(' '.join(current_content).strip())\n",
    "                    if current_subsection in subsection_indexes:\n",
    "                        sections_with_content[section_index]['subsections'][subsection_indexes[current_subsection]]['content'] = subsection_content\n",
    "                    else:\n",
    "                        if current_subsection not in skip_tags:  # Skip subsection if in skip_tags\n",
    "                            sections_with_content[section_index]['subsections'].append({\n",
    "                                'content': subsection_content\n",
    "                            })\n",
    "                            subsection_indexes[current_subsection] = len(sections_with_content[section_index]['subsections']) - 1   \n",
    "                elif current_section and current_content:\n",
    "                    sections_with_content[-1]['content'] = clean_content(' '.join(current_content).strip())\n",
    "                    \n",
    "                \n",
    "                # handle no section or subsection detected\n",
    "                if not current_section and not current_subsection and current_content:\n",
    "                    current_section = \"Other Resources\"\n",
    "                    sections_with_content.append({\n",
    "                        'section': current_section,\n",
    "                        'subsections': [],\n",
    "                        'content': clean_content(' '.join(current_content).strip())\n",
    "                    })\n",
    "    return sections_with_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_subsection_content(sections):\n",
    "    for section in sections:\n",
    "        subsection_content = ' '.join([subsection['content'] for subsection in section['subsections']])\n",
    "        section['embedding_text'] = section['section'] + \" > \" + section['content'] + \" \" + subsection_content\n",
    "        \n",
    "        # Remove content and subsections\n",
    "        del section['content']\n",
    "        del section['subsections']\n",
    "    return sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_hyperlinks(hyperlinks, doc):\n",
    "    content = doc['embedding_text']\n",
    "    filtered_hyperlinks = []\n",
    "    for hyperlink in hyperlinks:\n",
    "        if hyperlink['text'].lower() in content.lower() and hyperlink['text'] != '':\n",
    "            filtered_hyperlinks.append(hyperlink)\n",
    "    return filtered_hyperlinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalize_document(hyperlinks, docs):\n",
    "    for doc in docs:\n",
    "        doc['hyperlinks'] = filter_hyperlinks(hyperlinks, doc)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PENDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"../data/prway.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pdfplumber.open(pdf_path) as pdf:\n",
    "    sample = []\n",
    "    for page in pdf.pages:\n",
    "        sample.append(page.extract_table())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " [['Progr\\nam\\n\\ue093 \\ue094',\n",
       "   'Langua\\nge\\nskills\\n\\ue093 \\ue094',\n",
       "   'Type of\\nwork\\nexperience\\n\\ue093 \\ue094',\n",
       "   'Amount of\\nwork\\nexperience\\n\\ue093 \\ue094',\n",
       "   'Job\\noffer \\ue093 \\ue094',\n",
       "   'Education\\n\\ue093 \\ue094'],\n",
       "  ['Atlant\\nic\\nImmi\\ngratio\\nn Pilot',\n",
       "   'You\\nhave\\ninterme\\ndiate\\nEnglish\\nor\\nFrench\\nskills\\n(CLB 4)',\n",
       "   'Not required',\n",
       "   'Not\\nrequired',\n",
       "   'Required\\nJob offer must\\nbe TEER\\ncategory\\n0, 1, 2, 3\\nor 4\\nlast at\\nleast 1\\nyear from\\nthe date\\npermane\\nnt\\nresidence\\nis\\ngranted\\nbe for an\\nemployer\\nin Atlantic\\nCanada',\n",
       "   'You must\\nhave\\ngraduated\\nfrom a\\npublicly\\nfunded\\npost-\\nsecondary\\ninstitution\\nin Atlantic\\nCanada\\nProgram\\nmust have\\nbeen at\\nleast 2\\nyears']],\n",
       " [['\\ue093 \\ue094',\n",
       "   '\\ue093 \\ue094',\n",
       "   '\\ue093 \\ue094',\n",
       "   '\\ue093 \\ue094',\n",
       "   '\\ue093 \\ue094',\n",
       "   '\\ue093 \\ue094'],\n",
       "  ['Cana\\ndian\\nExperi\\nence\\nClass',\n",
       "   'You\\nhave\\ninterme\\ndiate or\\nstrong\\nEnglish\\nor\\nFrench\\nskills\\n(CLB 7\\nif your\\nTEER is\\n0 or 1)\\n(CLB 5\\nif your\\nTEER is\\n2 or 3)',\n",
       "   'Canadian\\nexperience in\\n1 of these\\nTEER\\ncategories:\\n0\\n1\\n2\\n3',\n",
       "   '12 months\\n(combinatio\\nn of full-\\ntime or\\npart-time\\nwork)',\n",
       "   'Not required,\\nbut you can\\nget points for\\nhaving a valid\\noffer',\n",
       "   'Not\\nrequired,\\nbut you\\ncan get\\npoints for\\nyour\\nsecondary\\nor post-\\nsecondary\\neducation\\nYou can\\nget extra\\npoints if\\nyour\\neducation\\nis\\nCanadian']],\n",
       " [['\\ue093 \\ue094',\n",
       "   '\\ue093 \\ue094',\n",
       "   '\\ue093 \\ue094',\n",
       "   '\\ue093 \\ue094',\n",
       "   '\\ue093 \\ue094',\n",
       "   '\\ue093 \\ue094'],\n",
       "  ['Feder\\nal\\nSkille\\nd\\nTrade\\ns\\nProgr\\nam',\n",
       "   'You\\nhave\\ninterme\\ndiate\\nEnglish\\nor\\nFrench\\nskills\\n(CLB 5\\nfor\\nspeakin\\ng and\\nlistenin\\ng)\\n(CLB 4\\nfor\\nreading\\nand\\nwriting)',\n",
       "   'Experience in\\na skilled\\ntrade under\\nkey groups\\nof TEER 2 or\\n3',\n",
       "   '2 years\\nwithin last 5\\nyears',\n",
       "   'Required:\\nan offer\\nof full-\\ntime\\nemploym\\nent for a\\ntotal\\nperiod of\\nat least 1\\nyear, or\\na\\ncertificate\\nof\\nqualificati\\non in that\\nskilled\\ntrade\\nissued by\\na\\nCanadian\\nprovincial\\nor\\nterritorial\\nauthority',\n",
       "   'Not\\nrequired,\\nbut you\\ncan get\\npoints for\\nyour\\nsecondary\\nor post-\\nsecondary\\neducation\\nYou can\\nget extra\\npoints if\\nyour\\neducation\\nis\\nCanadian']],\n",
       " [['\\ue093 \\ue094',\n",
       "   '\\ue093 \\ue094',\n",
       "   '\\ue093 \\ue094',\n",
       "   '\\ue093 \\ue094',\n",
       "   '\\ue093 \\ue094',\n",
       "   '\\ue093 \\ue094'],\n",
       "  ['Feder\\nal\\nSkille\\nd\\nWork\\ner\\nProgr\\nam',\n",
       "   'You\\nhave\\nstrong\\nEnglish\\nor\\nFrench\\nskills\\n(CLB 7)',\n",
       "   'Experience in\\nTEER\\n0\\n1\\n2\\n3',\n",
       "   '1 year\\ncontinuous\\n(combinatio\\nn of part-\\ntime, full-\\ntime or\\nmore than\\none job)',\n",
       "   'Not required,\\nbut you can\\nget points for\\nhaving a valid\\noffer',\n",
       "   'Secondary\\neducation\\nrequired.\\nYou can\\nget more\\npoints for\\nyour post-\\nsecondary\\neducation\\nYou can\\nget extra\\npoints if\\nyour\\neducation\\nis\\nCanadian']],\n",
       " [['\\ue093 \\ue094',\n",
       "   '\\ue093 \\ue094',\n",
       "   '\\ue093 \\ue094',\n",
       "   '\\ue093 \\ue094',\n",
       "   '\\ue093 \\ue094',\n",
       "   '\\ue093 \\ue094'],\n",
       "  ['Provi\\nncial\\nNomi\\nnee\\nProgr\\nam',\n",
       "   'You\\nhave\\nstrong\\nEnglish\\nor\\nFrench\\nskills\\nLevels\\nvary by\\nprovinc\\ne',\n",
       "   'It depends\\non the\\nprovince, but\\nincludes all\\nTEER\\ncategories',\n",
       "   'It depends\\non the\\nprovince',\n",
       "   'It depends on\\nthe province',\n",
       "   'It depends\\non the\\nprovince']],\n",
       " [['\\ue093 \\ue094',\n",
       "   '\\ue093 \\ue094',\n",
       "   '\\ue093 \\ue094',\n",
       "   '\\ue093 \\ue094',\n",
       "   '\\ue093 \\ue094',\n",
       "   '\\ue093 \\ue094'],\n",
       "  ['Rural\\nNorth\\nern\\nImmi\\ngratio\\nn Pilot',\n",
       "   'You\\nhave\\ninterme\\ndiate\\nEnglish\\nor\\nFrench\\nskills\\n(CLB 6\\nif your\\nTEER is\\n0 or 1)\\n(CLB 5\\nif your\\nTEER is\\n2 or 3)\\n(CLB 4\\nif your\\nTEER is\\n4 or 5)',\n",
       "   'International\\nstudents\\nwho studied\\nin the\\ncommunity\\nmay be\\nexempt from\\nwork\\nexperience\\nrequirement\\ns',\n",
       "   'Not\\nrequired\\nInternation\\nal students\\nwho\\nstudied in\\nthe\\ncommunity\\nmay be\\nexempt\\nfrom work\\nexperience\\nrequiremen\\nts.',\n",
       "   'Required\\nYou must\\nhave a\\npermanent\\njob offer to\\nwork in one\\nof the\\nparticipating\\ncommunities',\n",
       "   'Variable\\nSee the\\neligibility\\nrequireme\\nnts for\\nmore\\ninformatio\\nn.']]]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spacy_env)",
   "language": "python",
   "name": "spacy_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
